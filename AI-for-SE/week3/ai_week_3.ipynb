# Setup and Library Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

# Set style for plots
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 7)

# Loading and Exploring the Iris Dataset

print("Section 1: Data Loading and Initial Exploration ")

# Load the Iris dataset
iris = load_iris()
X = iris.data  # Features
y = iris.target # Target labels (species)
feature_names = iris.feature_names
target_names = iris.target_names

# Convert to a Pandas DataFrame for easier manipulation and visualization
df = pd.DataFrame(X, columns=feature_names)
df['species'] = y
df['species_name'] = df['species'].apply(lambda x: target_names[x])

#print the first 5 rows
print("Dataset Head:")
print(df.head())


#print about the information obtained in the dataset
print("\nDataset Info:")
df.info()


#print the dataset decription
print("\nDataset Description (Statistical Summary):")
print(df.describe())

#clean the data
print("\nMissing Values:")
print(df.isnull().sum()) # Check for missing values (Iris dataset is usually clean)


#Section 2: Exploratory Data Analysis (EDA) and Visualization

print("Section 2: Exploratory Data Analysis (EDA)")

#Histograms for each feature
print("\nGenerating Histograms for each feature...")
df.drop(['species', 'species_name'], axis=1).hist(bins=15, figsize=(15, 10), layout=(2, 2))
plt.suptitle('Histograms of Iris Features', y=1.02)
plt.tight_layout(rect=[0, 0.03, 1, 0.98])
plt.show()

#Box plots for each feature by species
print("\nGenerating Box Plots for each feature by species...")
plt.figure(figsize=(15, 10))
for i, feature in enumerate(feature_names):
    plt.subplot(2, 2, i + 1)
    sns.boxplot(x='species_name', y=feature, data=df)
    plt.title(f'Box Plot of {feature} by Species')
plt.tight_layout()
plt.show()

#Pair Plot (Scatterplot Matrix) - CRUCIAL FOR VISUALIZING CLASS SEPARABILITY
print("\nGenerating Pair Plot (takes a moment)...")
# Hue by 'species_name' to distinguish classes
sns.pairplot(df, hue='species_name', diag_kind='kde', markers=["o", "s", "D"])
plt.suptitle('Pair Plot of Iris Features by Species', y=1.02)
plt.show()

# 2.4 Correlation Heatmap
print("\nGenerating Correlation Heatmap...")
plt.figure(figsize=(8, 6))
correlation_matrix = df[feature_names].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Iris Features')
plt.show()

#Section 3: Classification Model Development (Scikit-learn)

print("Section 3: Scikit-learn Classification Models")

#Data Preparation for Scikit-learn
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
print(f"Training set shape: {X_train.shape}, Test set shape: {X_test.shape}")

#Initialize a dictionary to store models and their performances
models = {
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Logistic Regression': LogisticRegression(max_iter=200, solver='liblinear'), # solver 'liblinear' good for small datasets
    'Support Vector Machine': SVC(probability=True), # probability=True for consistent API with others
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42)
}

results = {}

#Train and Evaluate Each Model
for name, model in models.items():
    print(f"\n--- Training and Evaluating {name} ---")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    # precision, recall, f1-score, support for each class
    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=0)
    class_report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True, zero_division=0)
    conf_mat = confusion_matrix(y_test, y_pred)

    results[name] = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'classification_report': class_report,
        'confusion_matrix': conf_mat
    }

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Weighted Precision: {precision:.4f}")
    print(f"Weighted Recall: {recall:.4f}")
    print(f"Weighted F1-score: {f1:.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))

    # Visualize Confusion Matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_names, yticklabels=target_names)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix for {name}')
    plt.show()

#Hyperparameter Tuning (Example with K-Nearest Neighbors)
print("Hyperparameter Tuning (K-Nearest Neighbors Example)")
knn = KNeighborsClassifier()


# Define the parameter grid to search
param_grid = {
    'n_neighbors': [3, 5, 7, 9], # Number of neighbors
    'weights': ['uniform', 'distance'], # Weight function
    'metric': ['euclidean', 'manhattan'] # Distance metric
}

grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

print(f"Best parameters for KNN: {grid_search.best_params_}")
print(f"Best cross-validation accuracy for KNN: {grid_search.best_score_:.4f}")

# Evaluate tuned KNN on the test set
y_pred_tuned_knn = grid_search.best_estimator_.predict(X_test)
accuracy_tuned_knn = accuracy_score(y_test, y_pred_tuned_knn)
print(f"Test Accuracy of Tuned KNN: {accuracy_tuned_knn:.4f}")

#Section 4: Simple Neural Network (TensorFlow/Keras)

print("\n--- Section 4: Neural Network with TensorFlow/Keras ---")

# 4.1 Data Preprocessing for Neural Network
# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# One-hot encode target variable (for categorical crossentropy loss)
encoder = OneHotEncoder(sparse_output=False) # sparse_output=False for dense array
y_one_hot = encoder.fit_transform(y.reshape(-1, 1))

# Split the scaled and one-hot encoded data
X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(
    X_scaled, y_one_hot, test_size=0.3, random_state=42, stratify=y
)

print(f"NN Training features shape: {X_train_nn.shape}, NN Training labels shape: {y_train_nn.shape}")

# 4.2 Build the Neural Network Model
nn_model = Sequential([
    # Input layer and first hidden layer
    Dense(10, activation='relu', input_shape=(X_train_nn.shape[1],)), # 4 features
    # Second hidden layer
    Dense(8, activation='relu'),
    # Output layer: 3 units for 3 classes, softmax for multi-class probability
    Dense(len(target_names), activation='softmax')
])

# Compile the model
nn_model.compile(optimizer='adam',
                 loss='categorical_crossentropy', # Appropriate for one-hot encoded labels
                 metrics=['accuracy'])

nn_model.summary()

#Train the Neural Network
print("\nTraining Neural Network (this may take a moment)")
history = nn_model.fit(X_train_nn, y_train_nn,
                       epochs=100, # Number of training iterations
                       batch_size=16, # Number of samples per gradient update
                       validation_split=0.1, # Use a part of training data for validation
                       verbose=0) # Set to 1 for progress bar

#Evaluate the Neural Network
print("\nEvaluating Neural Network")
loss, accuracy_nn = nn_model.evaluate(X_test_nn, y_test_nn, verbose=0)
print(f"Neural Network Test Loss: {loss:.4f}")
print(f"Neural Network Test Accuracy: {accuracy_nn:.4f}")

# Generate classification report and confusion matrix for NN
y_pred_nn_prob = nn_model.predict(X_test_nn)
y_pred_nn = np.argmax(y_pred_nn_prob, axis=1) # Convert probabilities to class labels
y_true_nn = np.argmax(y_test_nn, axis=1) # Convert one-hot to class labels

print("\nNeural Network Classification Report:")
print(classification_report(y_true_nn, y_pred_nn, target_names=target_names, zero_division=0))

conf_mat_nn = confusion_matrix(y_true_nn, y_pred_nn)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat_nn, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Neural Network')
plt.show()

# Plot training history (accuracy and loss)
print("\nPlotting Neural Network Training History...")
plt.figure(figsize=(12, 5))

# Plot Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

print("End of week 3 assignment")
